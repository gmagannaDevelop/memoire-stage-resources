@article{Chevalier2020,
abstract = {The construction of models of biological networks from prior knowledge and experimental data often leads to a multitude of candidate models. Devising a single model from them can require arbitrary choices, which may lead to strong biases in subsequent predictions. We introduce here a methodology for a) synthesizing Boolean model ensembles satisfying a set of biologically relevant constraints and b) reasoning on the dynamics of the ensembles of models. The synthesis is performed using Answer-Set Programming, extending prior work to account for solution diversity and universal constraints on reachable fixed points, enabling an accurate specification of desired dynamics. The sampled models are then simulated and the results are aggregated through averaging or can be analyzed as a multi-dimensional distribution. We illustrate our approach on a previously published Boolean model of a molecular network regulating the cell fate decisions in cancer progression. It appears that the ensemble-based approach to Boolean modelling brings new insights on the variability of synergistic interacting mutations effect concerning propensity of a cancer cell to metastasize.},
author = {Chevalier, St{\'{e}}phanie and No{\"{e}}l, Vincent and Calzone, Laurence and Zinovyev, Andrei and Paulev{\'{e}}, Lo{\"{i}}c},
doi = {10.1007/978-3-030-60327-4_11},
isbn = {9783030603267},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {Stage M1 : scRNA-seq data},
pages = {193--209},
title = {{Synthesis and Simulation of Ensembles of Boolean Networks for Cell Fate Decision}},
volume = {12314 LNBI},
year = {2020}
}
@article{Rosenblatt1991,
abstract = {A general weak convergence theory is developed for time-sequential censored rank statistics in the two-sample problem of comparing time to failure between two treatment groups, such as in the case of a clinical trial in which patients enter serially and, after being randomly allocated to one of two treatments, are followed until they fail or withdraw from the study or until the study is terminated. Applications of the theory to time-sequential tests based on these censored rank statistics are also discussed.},
author = {Rosenblatt, Murray},
journal = {Annals of Statistics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {3},
pages = {1403--1433},
title = {{Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to The Annals of Statistics. {\textregistered} www.jstor.org}},
volume = {19},
year = {1991}
}
@article{Valmari1998,
abstract = {State space methods are one of the most important approaches to computer-aided analysis and verification of the behaviour of concurrent systems. In their basic form, they consist of enumerating and analysing the set of the states the system can ever reach. Unfortunately, the number of states of even a relatively small system is often far greater than can be handled in a realistic computer. The goal of this article is to analyse this state explosion problem from several perspectives. Many advanced state space methods alleviate the problem by using a subset or an abstraction of the set of states. Unfortunately, their use tends to restrict the set of analysis or verification questions that can be answered, making it impossible to discuss the methods without some taxonomy of the questions. Therefore, the article contains a lengthy discussion on alternative ways of stating analysis and verification questions, and algorithms for answering them. After that, many advanced state space methods are briefly described. The state explosion problem is investigated also from the computational complexity point of view.},
author = {Valmari, Antti},
doi = {10.1007/3-540-65306-6_21},
mendeley-groups = {Stage M1 : scRNA-seq data},
pages = {429--528},
title = {{The state explosion problem}},
year = {1998}
}
@article{Jung2017,
abstract = {Motivation: The identification of genes or molecular regulatory mechanisms implicated in biological processes often requires the discretization, and in particular booleanization, of gene expression measurements. However, currently used methods mostly classify each measurement into an active or inactive state regardless of its statistical support possibly leading to downstream analysis conclusions based on spurious booleanization results. Results: In order to overcome the lack of certainty inherent in current methodologies and to improve the process of discretization, we introduce RefBool, a reference-based algorithm for discretizing gene expression data. Instead of requiring each measurement to be classified as active or inactive, RefBool allows for the classification of a third state that can be interpreted as an intermediate expression of genes. Furthermore, each measurement is associated to a p- A nd q-value indicating the significance of each classification. Validation of RefBool on a neuroepithelial differentiation study and subsequent qualitative and quantitative comparison against 10 currently used methods supports its advantages and shows clear improvements of resulting clusterings. Availability and Implementation: The software is available as MATLAB files in the Supplementary Information and as an online repository (https://github.com/saschajung/RefBool).},
author = {Jung, Sascha and Hartmann, Andras and {Del Sol}, Antonio},
doi = {10.1093/bioinformatics/btx111},
issn = {14602059},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {13},
pages = {1953--1962},
pmid = {28334101},
title = {{RefBool: A reference-based algorithm for discretizing gene expression data}},
volume = {33},
year = {2017}
}
@article{Pauleve2020,
abstract = {Predicting biological systems' behaviors requires taking into account many molecular and genetic elements for which limited information is available past a global knowledge of their pairwise interactions. Logical modeling, notably with Boolean Networks (BNs), is a well-established approach that enables reasoning on the qualitative dynamics of networks. Several dynamical interpretations of BNs have been proposed. The synchronous and (fully) asynchronous ones are the most prominent, where the value of either all or only one component can change at each step. Here we prove that, besides being costly to analyze, these usual interpretations can preclude the prediction of certain behaviors observed in quantitative systems. We introduce an execution paradigm, the Most Permissive Boolean Networks (MPBNs), which offers the formal guarantee not to miss any behavior achievable by a quantitative model following the same logic. Moreover, MPBNs significantly reduce the complexity of dynamical analysis, enabling to model genome-scale networks.},
author = {Paulev{\'{e}}, Lo{\"{i}}c and Kol{\v{c}}{\'{a}}k, Juraj and Chatain, Thomas and Haar, Stefan},
doi = {10.1038/s41467-020-18112-5},
issn = {20411723},
journal = {Nature Communications},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pages = {1--7},
pmid = {32848126},
title = {{Reconciling qualitative, abstract, and scalable modeling of biological networks}},
volume = {11},
year = {2020}
}
@article{Assefa2020,
author = {Assefa, Alemu Takele and Vandesompele, Jo and Thas, Olivier},
mendeley-groups = {Stage M1 : scRNA-seq data},
pages = {1--38},
title = {{Supplementary Material to : ‘ SPsimSeq : semi-parametric simulation of bulk and single-cell RNA sequencing data '}},
year = {2020}
}
@article{Nestorowa2016,
abstract = {Maintenance of the blood system requires balanced cell fate decisions by hematopoietic stem and progenitor cells (HSPCs). Because cell fate choices are executed at the individual cell level, new single-cell profiling technologies offer exciting possibilities for mapping the dynamic molecular changes underlying HSPC differentiation. Here, we have used single-cell RNA sequencing to profile more than 1600 single HSPCs, and deep sequencing has enabled detection of an average of 6558 protein-coding genes per cell. Index sorting, in combination with broad sorting gates, allowed us to retrospectively assign cells to 12 commonly sorted HSPC phenotypes while also capturing intermediate cells typically excluded by conventional gating. We further show that independently generated single-cell data sets can be projected onto the single-cell resolution expression map to directly compare data from multiple groups and to build and refine new hypotheses. Reconstruction of differentiation trajectories reveals dynamic expression changes associated with early lymphoid, erythroid, and granulocyte-macrophage differentiation. The latter two trajectories were characterized by common upregulation of cell cycle and oxidative phosphorylation transcriptional programs. By using external spike-in controls, we estimate absolute messenger RNA (mRNA) levels per cell, showing for the first time that despite a general reduction in total mRNA, a subset of genes shows higher expression levels in immature stem cells consistent with active maintenance of the stem-cell state. Finally, we report the development of an intuitive Web interface as a new community resource to permit visualization of gene expression in HSPCs at single-cell resolution for any gene of choice.},
author = {Nestorowa, Sonia and Hamey, Fiona K. and {Pijuan Sala}, Blanca and Diamanti, Evangelia and Shepherd, Mairi and Laurenti, Elisa and Wilson, Nicola K. and Kent, David G. and G{\"{o}}ttgens, Berthold},
doi = {10.1182/blood-2016-05-716480},
issn = {15280020},
journal = {Blood},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {8},
pages = {e20--e31},
pmid = {27365425},
title = {{A single-cell resolution map of mouse hematopoietic stem and progenitor cell differentiation}},
volume = {128},
year = {2016}
}
@article{Assefa2020a,
abstract = {SPsimSeq is a semi-parametric simulation method to generate bulk and single-cell RNA-sequencing data. It is designed to simulate gene expression data with maximal retention of the characteristics of real data. It is reasonably flexible to accommodate a wide range of experimental scenarios, including different sample sizes, biological signals (differential expression) and confounding batch effects.},
author = {Assefa, Alemu Takele and Vandesompele, Jo and Thas, Olivier},
doi = {10.1093/bioinformatics/btaa105},
issn = {14602059},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {10},
pages = {3276--3278},
pmid = {32065619},
title = {{SPsimSeq: Semi-parametric simulation of bulk and single-cell RNA-sequencing data}},
volume = {36},
year = {2020}
}
@article{Chen2019,
abstract = {Single-cell transcriptomic assays have enabled the de novo reconstruction of lineage differentiation trajectories, along with the characterization of cellular heterogeneity and state transitions. Several methods have been developed for reconstructing developmental trajectories from single-cell transcriptomic data, but efforts on analyzing single-cell epigenomic data and on trajectory visualization remain limited. Here we present STREAM, an interactive pipeline capable of disentangling and visualizing complex branching trajectories from both single-cell transcriptomic and epigenomic data. We have tested STREAM on several synthetic and real datasets generated with different single-cell technologies. We further demonstrate its utility for understanding myoblast differentiation and disentangling known heterogeneity in hematopoiesis for different organisms. STREAM is an open-source software package.},
author = {Chen, Huidong and Albergante, Luca and Hsu, Jonathan Y. and Lareau, Caleb A. and {Lo Bosco}, Giosu{\`{e}} and Guan, Jihong and Zhou, Shuigeng and Gorban, Alexander N. and Bauer, Daniel E. and Aryee, Martin J. and Langenau, David M. and Zinovyev, Andrei and Buenrostro, Jason D. and Yuan, Guo Cheng and Pinello, Luca},
doi = {10.1038/s41467-019-09670-4},
issn = {20411723},
journal = {Nature Communications},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pmid = {31015418},
publisher = {Springer US},
title = {{Single-cell trajectories reconstruction, exploration and mapping of omics data with STREAM}},
url = {http://dx.doi.org/10.1038/s41467-019-09670-4},
volume = {10},
year = {2019}
}
@article{Margolin2013,
abstract = {Although molecular prognostics in breast cancer are among the most successful examples of translating genomic analysis to clinical applications, optimal approaches to breast cancer clinical risk prediction remain controversial. The Sage Bionetworks-DREAM Breast Cancer Prognosis Challenge (BCC) is a crowdsourced research study for breast cancer prognostic modeling using genome-scale data. The BCC provided a community of data analysts with a common platform for data access and blinded evaluation of model accuracy in predicting breast cancer survival on the basis of gene expression data, copy number data, and clinical covariates. This approach offered the opportunity to assess whether a crowdsourced community Challenge would generate models of breast cancer prognosis commensurate with or exceeding current best-in-class approaches. The BCC comprised multiple rounds of blinded evaluations on held-out portions of data on 1981 patients, resulting in more than 1400 models submitted as open source code. Participants then retrained their models on the full data set of 1981 samples and submitted up to five models for validation in a newly generated data set of 184 breast cancer patients. Analysis of the BCC results suggests that the best-performing modeling strategy outperformed previously reported methods in blinded evaluations; model performance was consistent across several independent evaluations; and aggregating community-developed models achieved performance on par with the best-performing individual models. Copyright 2013 by the American Association for the Advancement of Science; all rights reserved.},
author = {Margolin, Adam A. and Bilal, Erhan and Huang, Erich and Norman, Thea C. and Ottestad, Lars and Mecham, Brigham H. and Sauerwine, Ben and Kellen, Michael R. and Mangravite, Lara M. and Furia, Matthew D. and Vollan, Hans Kristian Moen and Rueda, Oscar M. and Guinney, Justin and Deflaux, Nicole A. and Hoff, Bruce and Schildwachter, Xavier and Russnes, Hege G. and Park, Daehoon and Vang, Veronica O. and Pirtle, Tyler and Youseff, Lamia and Citro, Craig and Curtis, Christina and Kristensen, Vessela N. and Hellerstein, Joseph and Friend, Stephen H. and Stolovitzky, Gustavo and Aparicio, Samuel and Caldas, Carlos and B{\o}rresen-Dale, Anne Lise},
doi = {10.1126/scitranslmed.3006112},
issn = {19466234},
journal = {Science Translational Medicine},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {181},
pmid = {23596205},
title = {{Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer}},
volume = {5},
year = {2013}
}
@article{Baruzzo2020,
abstract = {Motivation: Single cell RNA-seq (scRNA-seq) count data show many differences compared with bulk RNA-seq count data, making the application of many RNA-seq pre-processing/analysis methods not straightforward or even inappropriate. For this reason, the development of new methods for handling scRNA-seq count data is currently one of the most active research fields in bioinformatics. To help the development of such new methods, the availability of simulated data could play a pivotal role. However, only few scRNA-seq count data simulators are available, often showing poor or not demonstrated similarity with real data. Results: In this article we present SPARSim, a scRNA-seq count data simulator based on a Gamma-Multivariate Hypergeometric model. We demonstrate that SPARSim allows to generate count data that resemble real data in terms of count intensity, variability and sparsity, performing comparably or better than one of the most used scRNA-seq simulator, Splat. In particular, SPARSim simulated count matrices well resemble the distribution of zeros across different expression intensities observed in real count data.},
author = {Baruzzo, Giacomo and Patuzzi, Ilaria and {Di Camillo}, Barbara},
doi = {10.1093/bioinformatics/btz752},
issn = {14602059},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {5},
pages = {1468--1475},
pmid = {31598633},
title = {{SPARSim single cell: A count data simulator for scRNA-seq data}},
volume = {36},
year = {2020}
}
@article{Conesa2016,
abstract = {RNA-sequencing (RNA-seq) has a wide variety of applications, but no single analysis pipeline can be used in all cases. We review all of the major steps in RNA-seq data analysis, including experimental design, quality control, read alignment, quantification of gene and transcript levels, visualization, differential gene expression, alternative splicing, functional analysis, gene fusion detection and eQTL mapping. We highlight the challenges associated with each step. We discuss the analysis of small RNAs and the integration of RNA-seq with other functional genomics techniques. Finally, we discuss the outlook for novel technologies that are changing the state of the art in transcriptomics.},
author = {Conesa, Ana and Madrigal, Pedro and Tarazona, Sonia and Gomez-Cabrero, David and Cervera, Alejandra and McPherson, Andrew and Szcze{\'{s}}niak, Michal Wojciech and Gaffney, Daniel J. and Elo, Laura L. and Zhang, Xuegong and Mortazavi, Ali},
doi = {10.1186/s13059-016-0881-8},
issn = {1474760X},
journal = {Genome Biology},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pages = {1--19},
pmid = {26813401},
title = {{A survey of best practices for RNA-seq data analysis}},
volume = {17},
year = {2016}
}
@article{Dibaeinia2020,
abstract = {We present SERGIO, a software tool that can simulate realistic single-cell transcriptomics datasets based on a user-specified gene regulatory network (GRN). Datasets simulated using SERGIO can be used to benchmark a variety of single-cell analysis tools, especially GRN inference methods.},
author = {Dibaeinia, Payam and Sinha, Saurabh},
doi = {10.1016/j.cels.2020.08.003},
issn = {24054720},
journal = {Cell Systems},
keywords = {RNA velocity,benchmarking single-cell analysis tools,differentiation trajectories,gene regulatory networks,simulations,single-cell RNA-seq},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {3},
pages = {252--271.e11},
pmid = {32871105},
publisher = {Elsevier Inc.},
title = {{SERGIO: A Single-Cell Expression Simulator Guided by Gene Regulatory Networks}},
url = {https://doi.org/10.1016/j.cels.2020.08.003},
volume = {11},
year = {2020}
}
@article{Tong2020,
abstract = {To use next-generation sequencing technology such as RNA-seq for medical and health applications, choosing proper analysis methods for biomarker identification remains a critical challenge for most users. The US Food and Drug Administration (FDA) has led the Sequencing Quality Control (SEQC) project to conduct a comprehensive investigation of 278 representative RNA-seq data analysis pipelines consisting of 13 sequence mapping, three quantification, and seven normalization methods. In this article, we focused on the impact of the joint effects of RNA-seq pipelines on gene expression estimation as well as the downstream prediction of disease outcomes. First, we developed and applied three metrics (i.e., accuracy, precision, and reliability) to quantitatively evaluate each pipeline's performance on gene expression estimation. We then investigated the correlation between the proposed metrics and the downstream prediction performance using two real-world cancer datasets (i.e., SEQC neuroblastoma dataset and the NIH/NCI TCGA lung adenocarcinoma dataset). We found that RNA-seq pipeline components jointly and significantly impacted the accuracy of gene expression estimation, and its impact was extended to the downstream prediction of these cancer outcomes. Specifically, RNA-seq pipelines that produced more accurate, precise, and reliable gene expression estimation tended to perform better in the prediction of disease outcome. In the end, we provided scenarios as guidelines for users to use these three metrics to select sensible RNA-seq pipelines for the improved accuracy, precision, and reliability of gene expression estimation, which lead to the improved downstream gene expression-based prediction of disease outcome.},
author = {Tong, Li and Wu, Po Yen and Phan, John H. and Hassazadeh, Hamid R. and Jones, Wendell D. and Shi, Leming and Fischer, Matthias and Mason, Christopher E. and Li, Sheng and Xu, Joshua and Shi, Wei and Wang, Jian and Thierry-Mieg, Jean and Thierry-Mieg, Danielle and Hertwig, Falk and Berthold, Frank and Hero, Barbara and Liao, Yang and Smyth, Gordon K. and Kreil, David and {\L}abaj, Pawe{\l} P. and Megherbi, Dalila and Schroth, Gary and Fang, Hong and Tong, Weida and Wang, May D.},
doi = {10.1038/s41598-020-74567-y},
isbn = {0123456789},
issn = {20452322},
journal = {Scientific Reports},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pages = {1--20},
pmid = {33087762},
title = {{Impact of RNA-seq data analysis algorithms on gene expression estimation and downstream prediction}},
volume = {10},
year = {2020}
}
@article{Beal2019a,
abstract = {Logical models of cancer pathways are typically built by mining the literature for relevant experimental observations. They are usually generic as they apply for large cohorts of individuals. As a consequence, they generally do not capture the heterogeneity of patient tumors and their therapeutic responses. We present here a novel framework, referred to as PROFILE, to tailor logical models to a particular biological sample such as a patient tumor. This methodology permits to compare the model simulations to individual clinical data, i.e., survival time. Our approach focuses on integrating mutation data, copy number alterations (CNA), and expression data (transcriptomics or proteomics) to logical models. These data need first to be either binarized or set between 0 and 1, and can then be incorporated in the logical model by modifying the activity of the node, the initial conditions or the state transition rates. The use of MaBoSS, a tool based on Monte-Carlo kinetic algorithm to perform stochastic simulations on logical models results in model state probabilities, and allows for a semi-quantitative study of the model phenotypes and perturbations. As a proof of concept, we use a published generic model of cancer signaling pathways and molecular data from METABRIC breast cancer patients. For this example, we test several combinations of data incorporation and discuss that, with these data, the most comprehensive patient-specific cancer models are obtained by modifying the nodes' activity of the model with mutations, in combination or not with CNA data, and altering the transition rates with RNA expression. We conclude that these model simulations show good correlation with clinical data such as patients' Nottingham prognostic index (NPI) subgrouping and survival time. We observe that two highly relevant cancer phenotypes derived from personalized models, Proliferation and Apoptosis, are biologically consistent prognostic factors: patients with both high proliferation and low apoptosis have the worst survival rate, and conversely. Our approach aims to combine the mechanistic insights of logical modeling with multi-omics data integration to provide patient-relevant models. This work leads to the use of logical modeling for precision medicine and will eventually facilitate the choice of patient-specific drug treatments by physicians.},
author = {Beal, Jonas and Montagud, Arnau and Traynard, Pauline and Barillot, Emmanuel and Calzone, Laurence},
doi = {10.3389/fphys.2018.01965},
issn = {1664042X},
journal = {Frontiers in Physiology},
keywords = {Breast cancer,Data discretization,Logical models,Personalized mechanistic models,Personalized medicine,Stochastic simulations},
mendeley-groups = {TER : BNeDiction,Stage M1 : scRNA-seq data},
number = {JAN},
pages = {1--23},
title = {{Personalization of logical models with multi-omics data allows clinical stratification of patients}},
volume = {10},
year = {2019}
}
@article{Kane2013,
abstract = {This paper presents two complementary statistical computing frameworks that address challenges in parallel processing and the analysis of massive data. First, the for each package allows users of the R programming environment to define parallel loops that may be run sequentially on a single machine, in parallel on a symmetric multiprocessing (SMP) machine, or in cluster environments without platform-specific code. Second, the big memory package implements memory- and file-mapped data structures that provide (a) access to arbitrarily large data while retaining a look and feel that is familiar to R users and (b) data structures that are shared across processor cores in order to support efficient parallel computing techniques. Although these packages may be used independently, this paper shows how they can be used in combination to address challenges that have effectively been beyond the reach of researchers who lack specialized software development skills or expensive hardware.},
author = {Kane, Michael J. and Emerson, John W. and Weston, Stephen},
doi = {10.18637/jss.v055.i14},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Concurrent programming,Memory-mapping,Parallel programming,Shared memory,Statistical computing},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {14},
pages = {1--19},
title = {{Scalable strategies for computing with massive data}},
volume = {55},
year = {2013}
}
@article{Beal2019,
abstract = {Logical models of cancer pathways are typically built by mining the literature for relevant experimental observations. They are usually generic as they apply for large cohorts of individuals. As a consequence, they generally do not capture the heterogeneity of patient tumors and their therapeutic responses. We present here a novel framework, referred to as PROFILE, to tailor logical models to a particular biological sample such as a patient tumor. This methodology permits to compare the model simulations to individual clinical data, i.e., survival time. Our approach focuses on integrating mutation data, copy number alterations (CNA), and expression data (transcriptomics or proteomics) to logical models. These data need first to be either binarized or set between 0 and 1, and can then be incorporated in the logical model by modifying the activity of the node, the initial conditions or the state transition rates. The use of MaBoSS, a tool based on Monte-Carlo kinetic algorithm to perform stochastic simulations on logical models results in model state probabilities, and allows for a semi-quantitative study of the model phenotypes and perturbations. As a proof of concept, we use a published generic model of cancer signaling pathways and molecular data from METABRIC breast cancer patients. For this example, we test several combinations of data incorporation and discuss that, with these data, the most comprehensive patient-specific cancer models are obtained by modifying the nodes' activity of the model with mutations, in combination or not with CNA data, and altering the transition rates with RNA expression. We conclude that these model simulations show good correlation with clinical data such as patients' Nottingham prognostic index (NPI) subgrouping and survival time. We observe that two highly relevant cancer phenotypes derived from personalized models, Proliferation and Apoptosis, are biologically consistent prognostic factors: patients with both high proliferation and low apoptosis have the worst survival rate, and conversely. Our approach aims to combine the mechanistic insights of logical modeling with multi-omics data integration to provide patient-relevant models. This work leads to the use of logical modeling for precision medicine and will eventually facilitate the choice of patient-specific drug treatments by physicians.},
author = {Beal, Jonas and Montagud, Arnau and Traynard, Pauline and Barillot, Emmanuel and Calzone, Laurence},
doi = {10.3389/fphys.2018.01965},
issn = {1664042X},
journal = {Frontiers in Physiology},
keywords = {Breast cancer,Data discretization,Logical models,Personalized mechanistic models,Personalized medicine,Stochastic simulations},
mendeley-groups = {TER : BNeDiction,Stage M1 : scRNA-seq data},
number = {JAN},
title = {{Personalization of logical models with multi-omics data allows clinical stratification of patients}},
volume = {10},
year = {2019}
}
@article{Martino2012,
abstract = {Many practical simulation tasks demand procedures to draw samples efficiently from multivariate truncated Gaussian distributions. Introduced is a novel rejection approach, based on the Box-Muller transformation, to generate samples from a truncated bivariate Gaussian density with an arbitrary support. Furthermore, for an important class of support regions the new method allows exact sampling to be achieved, thus becoming the most efficient approach possible. {\textcopyright} 2012 The Institution of Engineering and Technology.},
author = {Martino, L. and Luengo, D. and M{\'{i}}guez, J.},
doi = {10.1049/el.2012.2816},
issn = {00135194},
journal = {Electronics Letters},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {24},
pages = {1533--1534},
title = {{Efficient sampling from truncated bivariate Gaussians via Box-Muller transformation}},
volume = {48},
year = {2012}
}
@article{Hou2020,
abstract = {Background: The rapid development of single-cell RNA-sequencing (scRNA-seq) technologies has led to the emergence of many methods for removing systematic technical noises, including imputation methods, which aim to address the increased sparsity observed in single-cell data. Although many imputation methods have been developed, there is no consensus on how methods compare to each other. Results: Here, we perform a systematic evaluation of 18 scRNA-seq imputation methods to assess their accuracy and usability. We benchmark these methods in terms of the similarity between imputed cell profiles and bulk samples and whether these methods recover relevant biological signals or introduce spurious noise in downstream differential expression, unsupervised clustering, and pseudotemporal trajectory analyses, as well as their computational run time, memory usage, and scalability. Methods are evaluated using data from both cell lines and tissues and from both plate- and droplet-based single-cell platforms. Conclusions: We found that the majority of scRNA-seq imputation methods outperformed no imputation in recovering gene expression observed in bulk RNA-seq. However, the majority of the methods did not improve performance in downstream analyses compared to no imputation, in particular for clustering and trajectory analysis, and thus should be used with caution. In addition, we found substantial variability in the performance of the methods within each evaluation aspect. Overall, MAGIC, kNN-smoothing, and SAVER were found to outperform the other methods most consistently.},
author = {Hou, Wenpin and Ji, Zhicheng and Ji, Hongkai and Hicks, Stephanie C.},
doi = {10.1186/s13059-020-02132-x},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Benchmark,Gene expression,Imputation,Single-cell RNA-sequencing},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pages = {1--30},
pmid = {32854757},
publisher = {Genome Biology},
title = {{A systematic evaluation of single-cell RNA-sequencing imputation methods}},
volume = {21},
year = {2020}
}
@article{Chen2019,
abstract = {Single-cell transcriptomic assays have enabled the de novo reconstruction of lineage differentiation trajectories, along with the characterization of cellular heterogeneity and state transitions. Several methods have been developed for reconstructing developmental trajectories from single-cell transcriptomic data, but efforts on analyzing single-cell epigenomic data and on trajectory visualization remain limited. Here we present STREAM, an interactive pipeline capable of disentangling and visualizing complex branching trajectories from both single-cell transcriptomic and epigenomic data. We have tested STREAM on several synthetic and real datasets generated with different single-cell technologies. We further demonstrate its utility for understanding myoblast differentiation and disentangling known heterogeneity in hematopoiesis for different organisms. STREAM is an open-source software package.},
author = {Chen, Huidong and Albergante, Luca and Hsu, Jonathan Y. and Lareau, Caleb A. and {Lo Bosco}, Giosu{\`{e}} and Guan, Jihong and Zhou, Shuigeng and Gorban, Alexander N. and Bauer, Daniel E. and Aryee, Martin J. and Langenau, David M. and Zinovyev, Andrei and Buenrostro, Jason D. and Yuan, Guo Cheng and Pinello, Luca},
doi = {10.1038/s41467-019-09670-4},
issn = {20411723},
journal = {Nature Communications},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pmid = {31015418},
publisher = {Springer US},
title = {{Single-cell trajectories reconstruction, exploration and mapping of omics data with STREAM}},
url = {http://dx.doi.org/10.1038/s41467-019-09670-4},
volume = {10},
year = {2019}
}
@article{Booeshaghi2021,
abstract = {  Single-cell RNA-seq technologies have been successfully employed over the past decade to generate many high resolution cell atlases. These have proved invaluable in recent efforts aimed at understanding the cell type specificity of host genes involved in SARS-CoV-2 infections. While single-cell atlases are based on well-sampled highly-expressed genes, many of the genes of interest for understanding SARS-CoV-2 can be expressed at very low levels. Common assumptions underlying standard single-cell analyses don't hold when examining low-expressed genes, with the result that standard workflows can produce misleading results. SUPPLEMENTARY INFORMATION Supplementary data and all of the code to reproduce Figure 1 are available here: https://github.com/pachterlab/BP_2020_2/.},
author = {Booeshaghi, A Sina and Pachter, Lior},
doi = {10.1093/bioinformatics/btab085},
issn = {1367-4803},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
pages = {4--6},
pmid = {33676365},
title = {{ Normalization of single-cell RNA-seq counts by log( x + 1)† or log(1 + x )† }},
year = {2021}
}
@article{Roncalli2021,
abstract = {This article is part of a comprehensive research project on liquidity risk in asset management, which can be divided into three dimensions. The first dimension covers liability liquidity risk (or funding liquidity) modeling, the second dimension focuses on asset liquidity risk (or market liquidity) modeling, and the third dimension considers asset-liability liquidity risk management (or asset-liability matching). The purpose of this research is to propose a methodological and practical framework in order to perform liquidity stress testing programs, which comply with regulatory guidelines (ESMA, 2019) and are useful for fund managers. The review of the academic literature and professional research studies shows that there is a lack of standardized and analytical models. The aim of this research project is then to fill the gap with the goal to develop mathematical and statistical approaches, and provide appropriate answers. In this first part that focuses on liability liquidity risk modeling, we propose several statistical models for estimating redemption shocks. The historical approach must be complemented by an analytical approach based on zero-inflated models if we want to understand the true parameters that influence the redemption shocks. Moreover, we must also distinguish aggregate population models and individual-based models if we want to develop behavioral approaches. Once these different statistical models are calibrated, the second big issue is the risk measure to assess normal and stressed redemption shocks. Finally, the last issue is to develop a factor model that can translate stress scenarios on market risk factors into stress scenarios on fund liabilities.},
author = {Roncalli, Thierry and Karray-Meziou, Fatma and Pan, Fran{\c{c}}ois and Regnault, Margaux},
doi = {10.2139/ssrn.3749184},
journal = {SSRN Electronic Journal},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {December 2020},
title = {{Liquidity Stress Testing in Asset Management, Part 1. Modeling the Liability Liquidity Risk}},
year = {2021}
}
@book{Lahnemann2020,
abstract = {The recent boom in microfluidics and combinatorial indexing strategies, combined with low sequencing costs, has empowered single-cell sequencing technology. Thousands - or even millions - of cells analyzed in a single experiment amount to a data revolution in single-cell biology and pose unique data science problems. Here, we outline eleven challenges that will be central to bringing this emerging field of single-cell data science forward. For each challenge, we highlight motivating research questions, review prior work, and formulate open problems. This compendium is for established researchers, newcomers, and students alike, highlighting interesting and rewarding problems for the coming years.},
author = {L{\"{a}}hnemann, David and K{\"{o}}ster, Johannes and Szczurek, Ewa and McCarthy, Davis J. and Hicks, Stephanie C. and Robinson, Mark D. and Vallejos, Catalina A. and Campbell, Kieran R. and Beerenwinkel, Niko and Mahfouz, Ahmed and Pinello, Luca and Skums, Pavel and Stamatakis, Alexandros and Attolini, Camille Stephan Otto and Aparicio, Samuel and Baaijens, Jasmijn and Balvert, Marleen and de Barbanson, Buys and Cappuccio, Antonio and Corleone, Giacomo and Dutilh, Bas E. and Florescu, Maria and Guryev, Victor and Holmer, Rens and Jahn, Katharina and Lobo, Thamar Jessurun and Keizer, Emma M. and Khatri, Indu and Kielbasa, Szymon M. and Korbel, Jan O. and Kozlov, Alexey M. and Kuo, Tzu Hao and Lelieveldt, Boudewijn P.F. and Mandoiu, Ion I. and Marioni, John C. and Marschall, Tobias and M{\"{o}}lder, Felix and Niknejad, Amir and Raczkowski, Lukasz and Reinders, Marcel and de Ridder, Jeroen and Saliba, Antoine Emmanuel and Somarakis, Antonios and Stegle, Oliver and Theis, Fabian J. and Yang, Huan and Zelikovsky, Alex and McHardy, Alice C. and Raphael, Benjamin J. and Shah, Sohrab P. and Sch{\"{o}}nhuth, Alexander},
booktitle = {Genome Biology},
doi = {10.1186/s13059-020-1926-6},
isbn = {1305902019266},
issn = {1474760X},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {1},
pages = {1--35},
pmid = {32033589},
publisher = {Genome Biology},
title = {{Eleven grand challenges in single-cell data science}},
volume = {21},
year = {2020}
}
@article{Tang2020,
abstract = {Motivation: Normalization of single-cell RNA-sequencing (scRNA-seq) data is a prerequisite to their interpretation. The marked technical variability, high amounts of missing observations and batch effect typical of scRNA-seq datasets make this task particularly challenging. There is a need for an efficient and unified approach for normalization, imputation and batch effect correction. Results: Here, we introduce bayNorm, a novel Bayesian approach for scaling and inference of scRNA-seq counts. The method's likelihood function follows a binomial model of mRNA capture, while priors are estimated from expression values across cells using an empirical Bayes approach. We first validate our assumptions by showing this model can reproduce different statistics observed in real scRNA-seq data. We demonstrate using publicly available scRNA-seq datasets and simulated expression data that bayNorm allows robust imputation of missing values generating realistic transcript distributions that match single molecule fluorescence in situ hybridization measurements. Moreover, by using priors informed by dataset structures, bayNorm improves accuracy and sensitivity of differential expression analysis and reduces batch effect compared with other existing methods. Altogether, bayNorm provides an efficient, integrated solution for global scaling normalization, imputation and true count recovery of gene expression measurements from scRNA-seq data. Availability and implementation: The R package 'bayNorm' is publishd on bioconductor at https://bioconductor.org/packages/release/bioc/html/bayNorm.html. The code for analyzing data in this article is available at https://github. com/WT215/bayNorm_papercode.},
author = {Tang, Wenhao and Bertaux, Fran{\c{c}}ois and Thomas, Philipp and Stefanelli, Claire and Saint, Malika and Marguerat, Samuel and Shahrezaei, Vahid},
doi = {10.1093/bioinformatics/btz726},
issn = {14602059},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {4},
pages = {1174--1181},
pmid = {31584606},
title = {{BayNorm: Bayesian gene expression recovery, imputation and normalization for single-cell RNA-sequencing data}},
volume = {36},
year = {2020}
}
@article{Clivio2019,
abstract = {In single-cell RNA sequencing data, biological processes or technical factors may induce an overabundance of zero measurements. Existing probabilistic approaches to interpreting these data either model all genes as zero-inflated, or none. But the overabundance of zeros might be gene-specific. Hence, we propose the AutoZI model, which, for each gene, places a spike-and-slab prior on a mixture assignment between a negative binomial (NB) component and a zero-inflated negative binomial (ZINB) component. We approximate the posterior distribution under this model using variational inference, and employ Bayesian decision theory to decide whether each gene is zero-inflated. On simulated data, AutoZI outperforms the alternatives. On negative control data, AutoZI retrieves predictions consistent to a previous study on ERCC spike-ins and recovers similar results on control RNAs. Applied to several datasets and instances of the 10x Chromium protocol, AutoZI allows both biological and technical interpretations of zero-inflation. Finally, AutoZI's decisions on mouse embyronic stem-cells suggest that zero-inflation might be due to transcriptional bursting.},
author = {Clivio, Oscar and Lopez, Romain and Regier, Jeffrey and Gayoso, Adam and Jordan, Michael and Yosef, Nir},
doi = {10.1101/794875},
mendeley-groups = {Stage M1 : scRNA-seq data},
pages = {1--8},
title = {{Detecting Zero-Inflated Genes in Single-Cell Transcriptomics Data}},
year = {2019}
}
@article{Zhu2020,
abstract = {We developed 2DImpute, an imputation method for correcting false zeros (known as dropouts) in single-cell RNA-sequencing (scRNA-seq) data. It features preventing excessive correction by predicting the false zeros and imputing their values by making use of the interrelationships between both genes and cells in the expression matrix. We showed that 2DImpute outperforms several leading imputation methods by applying it on datasets from various scRNA-seq protocols. Contact: d.anastassiou@columbia.edu},
author = {Zhu, Kaiyi and Anastassiou, Dimitris},
doi = {10.1093/bioinformatics/btaa148},
issn = {14602059},
journal = {Bioinformatics},
mendeley-groups = {Stage M1 : scRNA-seq data},
number = {11},
pages = {3588--3589},
pmid = {32108864},
title = {{2DImpute: Imputation in single-cell RNA-seq data from correlations in two dimensions}},
volume = {36},
year = {2020}
}
@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2020},
  url = {https://www.R-project.org/},
}

@Manual{R-bigmemory,
  title = {bigmemory: Manage Massive Matrices with Shared Memory and Memory-Mapped
Files},
  author = {Michael J. Kane and John W. Emerson and Peter Haverty and Charles {Determan Jr.}},
  year = {2019},
  note = {R package version 4.5.36},
  url = {https://github.com/kaneplusplus/bigmemory},
}

@Manual{R-bookdown,
  title = {bookdown: Authoring Books and Technical Documents with R Markdown},
  author = {Yihui Xie},
  year = {2021},
  note = {https://github.com/rstudio/bookdown,
https://pkgs.rstudio.com/bookdown/},
}

@Manual{R-diptest,
  title = {diptest: Hartigan's Dip Test Statistic for Unimodality - Corrected},
  author = {Martin Maechler},
  year = {2021},
  note = {R package version 0.76-0},
  url = {https://github.com/mmaechler/diptest},
}

@Manual{R-doSNOW,
  title = {doSNOW: Foreach Parallel Adaptor for the snow Package},
  author = {Microsoft Corporation and Stephen Weston},
  year = {2020},
  note = {R package version 1.0.19},
  url = {https://CRAN.R-project.org/package=doSNOW},
}

@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2021},
  note = {R package version 1.0.7},
  url = {https://CRAN.R-project.org/package=dplyr},
}

@Manual{R-foreach,
  title = {foreach: Provides Foreach Looping Construct},
  author = {{Revolution Analytics} and Steve Weston}},
  year = {2020},
  note = {R package version 1.5.1},
  url = {https://github.com/RevolutionAnalytics/foreach},
}

@Manual{R-glue,
  title = {glue: Interpreted String Literals},
  author = {Jim Hester},
  year = {2020},
  note = {R package version 1.4.2},
  url = {https://CRAN.R-project.org/package=glue},
}

@Manual{R-here,
  title = {here: A Simpler Way to Find Your Files},
  author = {Kirill Müller},
  year = {2020},
  note = {R package version 1.0.1},
  url = {https://CRAN.R-project.org/package=here},
}

@Manual{R-iterators,
  title = {iterators: Provides Iterator Construct},
  author = {Revolution Analytics and Steve Weston},
  year = {2020},
  note = {R package version 1.0.13},
  url = {https://github.com/RevolutionAnalytics/iterators},
}

@Manual{R-knitr,
  title = {knitr: A General-Purpose Package for Dynamic Report Generation in R},
  author = {Yihui Xie},
  year = {2021},
  note = {R package version 1.33},
  url = {https://yihui.org/knitr/},
}

@Manual{R-magrittr,
  title = {magrittr: A Forward-Pipe Operator for R},
  author = {Stefan Milton Bache and Hadley Wickham},
  year = {2020},
  note = {R package version 2.0.1},
  url = {https://CRAN.R-project.org/package=magrittr},
}

@Manual{R-mclust,
  title = {mclust: Gaussian Mixture Modelling for Model-Based Clustering,
Classification, and Density Estimation},
  author = {Chris Fraley and Adrian E. Raftery and Luca Scrucca},
  year = {2020},
  note = {R package version 5.4.7},
  url = {https://mclust-org.github.io/mclust/},
}

@Manual{R-moments,
  title = {moments: Moments, cumulants, skewness, kurtosis and related tests},
  author = {Lukasz Komsta and Frederick Novomestky},
  year = {2015},
  note = {R package version 0.14},
  url = {https://CRAN.R-project.org/package=moments},
}

@Manual{R-renv,
  title = {renv: Project Environments},
  author = {Kevin Ushey},
  year = {2021},
  note = {R package version 0.12.5},
  url = {https://rstudio.github.io/renv/},
}

@Manual{R-rmarkdown,
  title = {rmarkdown: Dynamic Documents for R},
  author = {JJ Allaire and Yihui Xie and Jonathan McPherson and Javier Luraschi and Kevin Ushey and Aron Atkins and Hadley Wickham and Joe Cheng and Winston Chang and Richard Iannone},
  year = {2021},
  note = {R package version 2.9},
  url = {https://CRAN.R-project.org/package=rmarkdown},
}

@Manual{R-snow,
  title = {snow: Simple Network of Workstations},
  author = {Luke Tierney and A. J. Rossini and Na Li and H. Sevcikova},
  year = {2018},
  note = {R package version 0.4-3},
  url = {https://CRAN.R-project.org/package=snow},
}

@Manual{R-tibble,
  title = {tibble: Simple Data Frames},
  author = {Kirill Müller and Hadley Wickham},
  year = {2021},
  note = {R package version 3.1.2},
  url = {https://CRAN.R-project.org/package=tibble},
}

@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham},
  year = {2021},
  note = {R package version 1.1.3},
  url = {https://CRAN.R-project.org/package=tidyr},
}

@Article{bigmemory2013,
  title = {Scalable Strategies for Computing with Massive Data},
  author = {Michael J. Kane and John Emerson and Stephen Weston},
  journal = {Journal of Statistical Software},
  year = {2013},
  volume = {55},
  number = {14},
  pages = {1--19},
  url = {http://www.jstatsoft.org/v55/i14/},
}

@Book{bookdown2016,
  title = {bookdown: Authoring Books and Technical Documents with {R} Markdown},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2016},
  note = {ISBN 978-1138700109},
  url = {https://bookdown.org/yihui/bookdown},
}

@Book{knitr2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {https://yihui.org/knitr/},
}

@InCollection{knitr2014,
  booktitle = {Implementing Reproducible Computational Research},
  editor = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
  title = {knitr: A Comprehensive Tool for Reproducible Research in {R}},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  year = {2014},
  note = {ISBN 978-1466561595},
  url = {http://www.crcpress.com/product/isbn/9781466561595},
}

@Article{mclust2016,
  title = {{mclust} 5: clustering, classification and density estimation using {G}aussian finite mixture models},
  author = {Luca Scrucca and Michael Fop and T. Brendan Murphy and Adrian E. Raftery},
  journal = {The {R} Journal},
  year = {2016},
  volume = {8},
  number = {1},
  pages = {289--317},
  url = {https://doi.org/10.32614/RJ-2016-021},
}

@Book{rmarkdown2018,
  title = {R Markdown: The Definitive Guide},
  author = {Yihui Xie and J.J. Allaire and Garrett Grolemund},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2018},
  note = {ISBN 9781138359338},
  url = {https://bookdown.org/yihui/rmarkdown},
}

@Book{rmarkdown2020,
  title = {R Markdown Cookbook},
  author = {Yihui Xie and Christophe Dervieux and Emily Riederer},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2020},
  note = {ISBN 9780367563837},
  url = {https://bookdown.org/yihui/rmarkdown-cookbook},
}

